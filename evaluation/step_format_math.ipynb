{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Adding Thought Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Function to process each line and reformat it\n",
    "def reformat_jsonl(input_file, output_file):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        # Read each line (which is a JSON object)\n",
    "        for line in infile:\n",
    "            # Parse the JSON object\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            # Get the value of the 'solution' key\n",
    "            solution_value = data.get('solution', '')\n",
    "            \n",
    "            # Define the regex pattern to split on either double spaces or \". {capital letter}\",\n",
    "            # excluding cases like \"p.m.\" where the period is part of an abbreviation.\n",
    "            # The negative lookbehind (?<!\\b(?:p\\.m|i\\.e|e\\.g)) ensures that we don't split on these cases.\n",
    "            pattern = r'(?<!\\b(?:p\\.m|i\\.e|e\\.g))\\. (?=[A-Z])|\\.  '\n",
    "            \n",
    "            # Split the solution into sentences based on the pattern\n",
    "            sentences = re.split(pattern, solution_value)\n",
    "            \n",
    "            # Add a period to the end of each sentence\n",
    "            for i, sentence in enumerate(sentences):\n",
    "                if sentence and sentence[-1] != \".\":\n",
    "                    sentences[i] += '.'\n",
    "            \n",
    "            # patterns = [r'\\$ (?=[A-Z])', r'\\$\\$(?=[A-Z])', r'\\n\\n', r'\\n']\n",
    "            # replacements = ['$', '$$', '', '']\n",
    "            \n",
    "            # for i in range(len(patterns)):\n",
    "            #     new_sentences = []\n",
    "            #     for sentence in sentences:\n",
    "            #         temp_sentences = re.split(patterns[i], sentence)\n",
    "                    \n",
    "            #         if len(temp_sentences) > 1:\n",
    "            #             for temp_sentence in temp_sentences[:len(temp_sentences) - 1]:\n",
    "            #                 temp_sentence += replacements[i]\n",
    "            #                 new_sentences.append(temp_sentence)\n",
    "            #             new_sentences.append(temp_sentences[-1])\n",
    "            #         else:\n",
    "            #             new_sentences.append(sentence)\n",
    "            #     sentences = new_sentences\n",
    "            \n",
    "            pattern = r'\\$ (?=[A-Z])'\n",
    "            \n",
    "            new_sentences = []\n",
    "            for sentence in sentences:\n",
    "                temp_sentences = re.split(pattern, sentence)\n",
    "                \n",
    "                if len(temp_sentences) > 1:\n",
    "                    for temp_sentence in temp_sentences[:len(temp_sentences) - 1]:\n",
    "                        temp_sentence += \"$\"\n",
    "                        new_sentences.append(temp_sentence)\n",
    "                    new_sentences.append(temp_sentences[-1])\n",
    "                else:\n",
    "                    new_sentences.append(sentence)\n",
    "            sentences = new_sentences\n",
    "            \n",
    "            pattern = r'\\$\\$(?=[A-Z])'\n",
    "            \n",
    "            new_sentences = []\n",
    "            for sentence in sentences:\n",
    "                temp_sentences = re.split(pattern, sentence)\n",
    "                \n",
    "                if len(temp_sentences) > 1:\n",
    "                    for temp_sentence in temp_sentences[:len(temp_sentences) - 1]:\n",
    "                        temp_sentence += \"$$\"\n",
    "                        new_sentences.append(temp_sentence)\n",
    "                    new_sentences.append(temp_sentences[-1])\n",
    "                else:\n",
    "                    new_sentences.append(sentence)\n",
    "            sentences = new_sentences\n",
    "        \n",
    "            pattern = r'\\n\\n'\n",
    "            \n",
    "            new_sentences = []\n",
    "            for sentence in sentences:\n",
    "                temp_sentences = re.split(pattern, sentence)\n",
    "                \n",
    "                if len(temp_sentences) > 1:\n",
    "                    for temp_sentence in temp_sentences[:len(temp_sentences) - 1]:\n",
    "                        new_sentences.append(temp_sentence)\n",
    "                    new_sentences.append(temp_sentences[-1])\n",
    "                else:\n",
    "                    new_sentences.append(sentence)\n",
    "            sentences = new_sentences\n",
    "            \n",
    "            pattern = r'\\n'\n",
    "            \n",
    "            new_sentences = []\n",
    "            for sentence in sentences:\n",
    "                temp_sentences = re.split(pattern, sentence)\n",
    "                \n",
    "                if len(temp_sentences) > 1:\n",
    "                    for temp_sentence in temp_sentences[:len(temp_sentences) - 1]:\n",
    "                        new_sentences.append(temp_sentence)\n",
    "                    new_sentences.append(temp_sentences[-1])\n",
    "                else:\n",
    "                    new_sentences.append(sentence)\n",
    "            sentences = new_sentences\n",
    "            \n",
    "            # Reformat the sentences with \"Thought I: \" and \"\\n\\n\"\n",
    "            reformatted_solution = \"\"\n",
    "            for i, sentence in enumerate(sentences):\n",
    "                sentence = sentence.strip()  # Remove leading/trailing whitespaces\n",
    "                if sentence:  # Only add non-empty sentences\n",
    "                    reformatted_solution += f\"Thought {i + 1}: {sentence}\"\n",
    "                    # Add \"\\n\\n\" for all but the last sentence\n",
    "                    if i < len(sentences) - 1:\n",
    "                        reformatted_solution += \"\\n\\n\"\n",
    "            \n",
    "            # Update the 'solution' key with the new formatted string\n",
    "            data['solution'] = reformatted_solution\n",
    "            \n",
    "            # Modify the 'problem' key with the new sentence about thoughts\n",
    "            problem_value = data.get('question', '')\n",
    "            if len(sentences) == 1:\n",
    "                data['question'] = f\"{problem_value}\\n\\nPlease respond in the following format using at most {len(sentences)} thought:\\nThought 1: ...\\n\\nThought 2: ...\\n\\n...\"\n",
    "            else:\n",
    "                data['question'] = f\"{problem_value}\\n\\nPlease respond in the following format using at most {len(sentences)} thoughts:\\nThought 1: ...\\n\\nThought 2: ...\\n\\n...\"\n",
    "            \n",
    "            # Write the modified JSON object back to the output file\n",
    "            outfile.write(json.dumps(data) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory and file paths\n",
    "input_directory = 'data/math'\n",
    "output_directory = 'data/math_thoughts_updated'\n",
    "input_test_file = os.path.join(input_directory, 'test.jsonl')\n",
    "output_test_file = os.path.join(output_directory, 'test.jsonl')\n",
    "input_train_file = os.path.join(input_directory, 'train.jsonl')\n",
    "output_train_file = os.path.join(output_directory, 'train.jsonl')\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Call the function for both test and train files\n",
    "reformat_jsonl(input_test_file, output_test_file)\n",
    "reformat_jsonl(input_train_file, output_train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Function to process each line and reformat it\n",
    "def reformat_jsonl(input_file, output_file):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        # Read each line (which is a JSON object)\n",
    "        for line in infile:\n",
    "            # Parse the JSON object\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            # Get the value of the 'solution' key\n",
    "            solution_value = data.get('solution', '')\n",
    "            \n",
    "            # Define the regex pattern to split on either double spaces or \". {capital letter}\",\n",
    "            # excluding cases like \"p.m.\" where the period is part of an abbreviation.\n",
    "            # The negative lookbehind (?<!\\b(?:p\\.m|i\\.e|e\\.g)) ensures that we don't split on these cases.\n",
    "            pattern = r'(?<!\\b(?:p\\.m|i\\.e|e\\.g))\\. (?=[A-Z])|\\.  '\n",
    "            \n",
    "            # Split the solution into sentences based on the pattern\n",
    "            sentences = re.split(pattern, solution_value)\n",
    "            \n",
    "            # Add a period to the end of each sentence\n",
    "            for i, sentence in enumerate(sentences):\n",
    "                if sentence and sentence[-1] != \".\":\n",
    "                    sentences[i] += '.'\n",
    "            \n",
    "            # patterns = [r'\\$ (?=[A-Z])', r'\\$\\$(?=[A-Z])', r'\\n\\n', r'\\n']\n",
    "            # replacements = ['$', '$$', '', '']\n",
    "            \n",
    "            # for i in range(len(patterns)):\n",
    "            #     new_sentences = []\n",
    "            #     for sentence in sentences:\n",
    "            #         temp_sentences = re.split(patterns[i], sentence)\n",
    "                    \n",
    "            #         if len(temp_sentences) > 1:\n",
    "            #             for temp_sentence in temp_sentences[:len(temp_sentences) - 1]:\n",
    "            #                 temp_sentence += replacements[i]\n",
    "            #                 new_sentences.append(temp_sentence)\n",
    "            #             new_sentences.append(temp_sentences[-1])\n",
    "            #         else:\n",
    "            #             new_sentences.append(sentence)\n",
    "            #     sentences = new_sentences\n",
    "            \n",
    "            pattern = r'\\$ (?=[A-Z])'\n",
    "            \n",
    "            new_sentences = []\n",
    "            for sentence in sentences:\n",
    "                temp_sentences = re.split(pattern, sentence)\n",
    "                \n",
    "                if len(temp_sentences) > 1:\n",
    "                    for temp_sentence in temp_sentences[:len(temp_sentences) - 1]:\n",
    "                        temp_sentence += \"$\"\n",
    "                        new_sentences.append(temp_sentence)\n",
    "                    new_sentences.append(temp_sentences[-1])\n",
    "                else:\n",
    "                    new_sentences.append(sentence)\n",
    "            sentences = new_sentences\n",
    "            \n",
    "            pattern = r'\\$\\$(?=[A-Z])'\n",
    "            \n",
    "            new_sentences = []\n",
    "            for sentence in sentences:\n",
    "                temp_sentences = re.split(pattern, sentence)\n",
    "                \n",
    "                if len(temp_sentences) > 1:\n",
    "                    for temp_sentence in temp_sentences[:len(temp_sentences) - 1]:\n",
    "                        temp_sentence += \"$$\"\n",
    "                        new_sentences.append(temp_sentence)\n",
    "                    new_sentences.append(temp_sentences[-1])\n",
    "                else:\n",
    "                    new_sentences.append(sentence)\n",
    "            sentences = new_sentences\n",
    "        \n",
    "            pattern = r'\\n\\n'\n",
    "            \n",
    "            new_sentences = []\n",
    "            for sentence in sentences:\n",
    "                temp_sentences = re.split(pattern, sentence)\n",
    "                \n",
    "                if len(temp_sentences) > 1:\n",
    "                    for temp_sentence in temp_sentences[:len(temp_sentences) - 1]:\n",
    "                        new_sentences.append(temp_sentence)\n",
    "                    new_sentences.append(temp_sentences[-1])\n",
    "                else:\n",
    "                    new_sentences.append(sentence)\n",
    "            sentences = new_sentences\n",
    "            \n",
    "            # Reformat the sentences with \"Thought I: \" and \"\\n\\n\"\n",
    "            reformatted_solution = \"\"\n",
    "            for i, sentence in enumerate(sentences):\n",
    "                sentence = sentence.strip()  # Remove leading/trailing whitespaces\n",
    "                if sentence:  # Only add non-empty sentences\n",
    "                    reformatted_solution += f\"Thought {i + 1}: {sentence}\"\n",
    "                    # Add \"\\n\\n\" for all but the last sentence\n",
    "                    if i < len(sentences) - 1:\n",
    "                        reformatted_solution += \"\\n\\n\"\n",
    "            \n",
    "            # Update the 'solution' key with the new formatted string\n",
    "            data['solution'] = reformatted_solution\n",
    "            \n",
    "            # Modify the 'problem' key with the new sentence about thoughts\n",
    "            problem_value = data.get('problem', '')\n",
    "            if len(sentences) == 1:\n",
    "                data['problem'] = f\"{problem_value}\\n\\nPlease respond in the following format using at most {len(sentences)} thought:\\nThought 1: ...\\n\\nThought 2: ...\\n\\n...\"\n",
    "            else:\n",
    "                data['problem'] = f\"{problem_value}\\n\\nPlease respond in the following format using at most {len(sentences)} thoughts:\\nThought 1: ...\\n\\nThought 2: ...\\n\\n...\"\n",
    "            \n",
    "            # Write the modified JSON object back to the output file\n",
    "            outfile.write(json.dumps(data) + '\\n')\n",
    "\n",
    "# Define the directory and file paths\n",
    "input_directory = 'data/math'\n",
    "output_directory = 'data/math_thoughts_v2'\n",
    "input_test_file = os.path.join(input_directory, 'test.jsonl')\n",
    "output_test_file = os.path.join(output_directory, 'test.jsonl')\n",
    "input_train_file = os.path.join(input_directory, 'train.jsonl')\n",
    "output_train_file = os.path.join(output_directory, 'train.jsonl')\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Call the function for both test and train files\n",
    "reformat_jsonl(input_test_file, output_test_file)\n",
    "reformat_jsonl(input_train_file, output_train_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For new extended thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Function to process each line and reformat it\n",
    "def reformat_jsonl(input_file, output_file):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        # Read each line (which is a JSON object)\n",
    "        for line in infile:\n",
    "            # Parse the JSON object\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            # Get the value of the 'solution' key\n",
    "            solution_value = data.get('code', '')\n",
    "            \n",
    "            # Define the regex pattern to split on '\\n'\n",
    "            pattern = r'\\n'\n",
    "            \n",
    "            # Split the solution into sentences based on the pattern\n",
    "            sentences = re.split(pattern, solution_value)\n",
    "            \n",
    "            # Reformat the sentences with \"Thought I: \" and \"\\n\\n\"\n",
    "            reformatted_solution = \"\"\n",
    "            for i, sentence in enumerate(sentences):\n",
    "                sentence = sentence.strip()  # Remove leading/trailing whitespaces\n",
    "                if sentence:  # Only add non-empty sentences\n",
    "                    reformatted_solution += f\"Thought {i + 1}: {sentence}\"\n",
    "                    # Add \"\\n\\n\" for all but the last sentence\n",
    "                    if i < len(sentences) - 1:\n",
    "                        reformatted_solution += \"\\n\\n\"\n",
    "            \n",
    "            # Update the 'solution' key with the new formatted string\n",
    "            data['code'] = reformatted_solution\n",
    "            \n",
    "            # Modify the 'problem' key with the new sentence about thoughts\n",
    "            problem_value = data.get('question', '')\n",
    "            if len(sentences) == 1:\n",
    "                data['question'] = f\"{problem_value}\\n\\nPlease respond in the following format using at most {len(sentences)} thought:\\nThought 1: ...\\n\\nThought 2: ...\\n\\n...\"\n",
    "            else:\n",
    "                data['question'] = f\"{problem_value}\\n\\nPlease respond in the following format using at most {len(sentences)} thoughts:\\nThought 1: ...\\n\\nThought 2: ...\\n\\n...\"\n",
    "            \n",
    "            # Write the modified JSON object back to the output file\n",
    "            outfile.write(json.dumps(data) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = 'outputs/llama-3-1-8b-instruct/math_eval/math_thoughts'\n",
    "output_directory = 'outputs/llama-3-1-8b-instruct/math_eval/math_thoughts'\n",
    "input_math_thoughts_file = os.path.join(input_directory, 'combined_thoughts.jsonl')\n",
    "output_math_thoughts_file = os.path.join(output_directory, 'combined_stepped_thoughts.jsonl')\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "reformat_jsonl(input_math_thoughts_file, output_math_thoughts_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files have been combined into llama-3-1-8b-instruct/math_eval/math_thoughts/combined_thoughts.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "\n",
    "def process_json_line(line, max_length=500):\n",
    "    \"\"\"\n",
    "    Process a JSON line to meet the specified requirements.\n",
    "\n",
    "    Args:\n",
    "        line (str): A line from the JSONL file.\n",
    "        max_length (int): Maximum length of the \"code\" field.\n",
    "\n",
    "    Returns:\n",
    "        dict or None: Processed JSON object if it meets requirements, None otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = json.loads(line)\n",
    "\n",
    "        # 1. Only use examples where score is True\n",
    "        if not data.get(\"score\", [False])[0]:\n",
    "            return None\n",
    "\n",
    "        # 2. Cut out thoughts after the last \\boxed\n",
    "        if \"code\" in data and isinstance(data[\"code\"], list) and len(data[\"code\"]) > 0:\n",
    "            code_str = data[\"code\"][0]\n",
    "\n",
    "            # Use regex to find all occurrences of \\boxed{...}\n",
    "            boxed_matches = list(re.finditer(r\"\\\\boxed\\{.*?\\}\\$\", code_str))\n",
    "            if boxed_matches and len(boxed_matches) > 3:\n",
    "                last_boxed = boxed_matches[2]\n",
    "                code_str = code_str[:last_boxed.end() + 1]  # Slice up to the end of the 3rd \\boxed{...}\n",
    "            elif boxed_matches:\n",
    "                # Get the position after the last match\n",
    "                last_boxed = boxed_matches[-1]\n",
    "                code_str = code_str[:last_boxed.end() + 1]  # Slice up to the end of the last \\boxed{...}\n",
    "            else:\n",
    "                return None\n",
    "            \n",
    "            data[\"code\"] = code_str  # Convert code list[0] to string\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        # 3. Ensure \"code\" is < max_length and has boxed answer\n",
    "        if len(data[\"code\"]) > max_length:\n",
    "            data[\"code\"] = data[\"code\"][:max_length]\n",
    "            \n",
    "            if \"\\\\boxed{\" not in data[\"code\"]:\n",
    "                return None\n",
    "\n",
    "        # 4. Add \"system\" key\n",
    "        data[\"system\"] = \"Please reason step by step, and put your final answer within \\\\boxed{{}}.\"\n",
    "\n",
    "        return data\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Skipping invalid JSON line: {e}\")\n",
    "        return None\n",
    "\n",
    "def combine_jsonl_files(input_dirs, output_file, patterns, max_thought_lengths):\n",
    "    # Open the output file in write mode\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        # Iterate over each pattern\n",
    "        for input_dir in input_dirs:\n",
    "            for pattern, max_length in zip(patterns, max_thought_lengths):\n",
    "                # Construct the full search pattern\n",
    "                search_pattern = os.path.join(input_dir, pattern)\n",
    "                # Use glob to find all files matching the pattern\n",
    "                files = glob.glob(search_pattern)\n",
    "                files.sort()  # Optional: sort files for consistent ordering\n",
    "\n",
    "                if not files:\n",
    "                    continue\n",
    "\n",
    "                # Iterate through each file and write its contents to the output file\n",
    "                for file_path in files:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "                        for line in infile:\n",
    "                            processed_data = process_json_line(line, max_length)\n",
    "                            if processed_data:\n",
    "                                outfile.write(json.dumps(processed_data) + '\\n')\n",
    "    \n",
    "    print(f\"All files have been combined into {output_file}\")\n",
    "\n",
    "def generate_patterns(thought_sizes, max_thought_length, batch_start=0, batch_end=7500, step=500):\n",
    "    patterns = []\n",
    "    max_thought_lengths = []\n",
    "    for thought in thought_sizes:\n",
    "        for start in range(batch_start, batch_end, step):\n",
    "            end = start + step\n",
    "            pattern = f\"train_qwen25-math-cot_-1_seed0_t1.0_thoughts{thought}_data_collection_s{start}_e{end}.jsonl\"\n",
    "            patterns.append(pattern)\n",
    "            max_thought_lengths.append(thought * max_thought_length)\n",
    "    return patterns, max_thought_lengths\n",
    "\n",
    "batch_sizes = [16, 32, 64, 128]\n",
    "output_dir = \"llama-3-1-8b-instruct/math_eval/math_thoughts\"\n",
    "output_file = \"llama-3-1-8b-instruct/math_eval/math_thoughts/combined_thoughts.jsonl\"\n",
    "input_dirs = [\"llama-3-1-8b-instruct/math_eval/math\", \"llama-3-1-8b-instruct/math_eval/math/no_planner_data_collection\"]\n",
    "max_thought_length = 500\n",
    "patterns, max_thought_lengths = generate_patterns(batch_sizes, max_thought_length)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "combine_jsonl_files(input_dirs, output_file, patterns, max_thought_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files have been combined into llama-3-1-8b-instruct/math_eval/math_thoughts/combined_thoughts_128_only.jsonl\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [128]\n",
    "output_dir = \"llama-3-1-8b-instruct/math_eval/math_thoughts\"\n",
    "output_file = \"llama-3-1-8b-instruct/math_eval/math_thoughts/combined_thoughts_128_only.jsonl\"\n",
    "input_dirs = [\"llama-3-1-8b-instruct/math_eval/math\", \"llama-3-1-8b-instruct/math_eval/math/no_planner_data_collection\"]\n",
    "max_thought_length = 500\n",
    "patterns, max_thought_lengths = generate_patterns(batch_sizes, max_thought_length)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "combine_jsonl_files(input_dirs, output_file, patterns, max_thought_lengths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
